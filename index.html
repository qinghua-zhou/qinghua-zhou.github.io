<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
    <div style="text-align: center;">
        <img style="width:28%;max-width:100%" alt="profile photo" src="images/profile.png" class="hoverZoomLink">
    </div> 
    <title>Qinghua Zhou</title>

    <div style="text-align: center;">
    <div class="row w-100 justify-content-center">
            <a class="main_color" rel="me" href="https://scholar.google.com/citations?hl=en&user=VY_Ldu4AAAAJ&view_op=list_works&sortby=pubdate" target="_blank"><i class="ai ai-2x ai-google-scholar academic_icons_customize"></i></a>
            <a class="main_color" rel="me" href="https://github.com/qinghua-zhou" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a>
            <!-- <a class="main_color" rel="me" href="https://twitter.com/qinghua_zhou" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg></a> -->
            <a class="main_color" rel="me" href="https://orcid.org/0000-0002-3327-0440" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path class="st0" d="M12 0C5.372 0 0 5.372 0 12s5.372 12 12 12 12-5.372 12-12S18.628 0 12 0zM7.369 4.378c.525 0 .947.431.947.947s-.422.947-.947.947a.95.95 0 0 1-.947-.947c0-.525.422-.947.947-.947zm-.722 3.038h1.444v10.041H6.647V7.416zm3.562 0h3.9c3.712 0 5.344 2.653 5.344 5.025 0 2.578-2.016 5.025-5.325 5.025h-3.919V7.416zm1.444 1.303v7.444h2.297c3.272 0 4.022-2.484 4.022-3.722 0-2.016-1.284-3.722-4.097-3.722h-2.222z"></path></svg></a>
            <a class="main_color" rel="me" href="https://www.linkedin.com/in/qinghua-zhou-650855138/" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-linkedin"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle></svg></a>
            <a class="main_color" rel="me" href="files/qinghuazhou_cv.pdf" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="0.65" stroke-linecap="round" stroke-linejoin="round" class="feather feather-linkedin"><<path d="M3 24h19v-23h-1v22h-18v1zm17-24h-18v22h18v-22zm-1 1h-16v20h16v-20zm-2 16h-12v1h12v-1zm0-3h-12v1h12v-1zm0-3h-12v1h12v-1zm-7.348-3.863l.948.3c-.145.529-.387.922-.725 1.178-.338.257-.767.385-1.287.385-.643 0-1.171-.22-1.585-.659-.414-.439-.621-1.04-.621-1.802 0-.806.208-1.432.624-1.878.416-.446.963-.669 1.642-.669.592 0 1.073.175 1.443.525.221.207.386.505.496.892l-.968.231c-.057-.251-.177-.449-.358-.594-.182-.146-.403-.218-.663-.218-.359 0-.65.129-.874.386-.223.258-.335.675-.335 1.252 0 .613.11 1.049.331 1.308.22.26.506.39.858.39.26 0 .484-.082.671-.248.187-.165.322-.425.403-.779zm3.023 1.78l-1.731-4.842h1.06l1.226 3.584 1.186-3.584h1.037l-1.734 4.842h-1.044z"/></svg></a></div>

    </div>

    <div style="text-align: center;">

        <div class="row w-100 justify-content-center main_color" id="full_name">Qinghua Zhou</div>
        <div class="affiliations row w-100 justify-content-center"><div class="row w-100 justify-content-center"><div class="row w-100 justify-content-center" id="title-name"><span class="main_color" id="title">Post-Doc Research Associate,
        </span><span id="name" class="text-muted">King's College London</span></div>
        <div class="row w-100 justify-content-center text-muted" id="email">
            <a href="mailto:qinghua.zhou@kcl.ac.uk" class="text-muted email-link">qinghua.zhou@kcl.ac.uk</a>
        </div></div></div>
    </div>
    <meta name="viewport" content="width=device-width, initial-scale=1">
  
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/seal_icon.png">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
    <script src="https://kit.fontawesome.com/66cbe15661.js" crossorigin="anonymous"></script>
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px"><td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p>I am  a researcher working in the fields of machine learning and artificial intelligence. My research interests lies in exploring pathways towards robust, stable and trustworthy AI systems. This includes the development of high-performance software and efficient scaling of large-scale simulations. My most current work is on the principled theoretical and computational analysis of modern computer vision and large language models, their <a href="https://ieeexplore.ieee.org/abstract/document/9892337">structures</a>, <a href="https://www.sciencedirect.com/science/article/pii/S089360802400635X">functions</a>, <a href="https://ieeexplore.ieee.org/document/10191304">optimization</a>, and methods to <a href="https://huggingface.co/spaces/qinghua-zhou/stealth-edits" style="color: magenta;">edit or attack</a> them.</p>

                <p>I am currently working as a <a href="https://kclpure.kcl.ac.uk/portal/en/persons/qinghua.zhou">Postdoctoral Research Associate in Methods and Algorithms of AI</a> in the Department of Mathematics at <a href="https://www.kcl.ac.uk/">King's College London (KCL)</a>, where I’m fortunate to work with <a href="https://oliversutton.info/">Dr Oliver J. Sutton</a> and be advised by <a href="https://www.kcl.ac.uk/people/ivan-tyukin-1">Prof. Ivan Y. Tyukin</a>. I have received a PhD from the <a href="https://le.ac.uk/">University of Leicester</a> with a focus on learning from high-dimensional low-sample size data in medical applications. Before that, I received a Bachelor of Science degree from the <a href="https://www.sydney.edu.au/">University of Sydney (USYD)</a>, majoring in both Physics and Applied Mathematics, with an introduction to scientific research through the lens of Asteroseismology.</p>
                
                <!-- <p>My broad interest in the field of AI has led to practical experiences in a wide variety of domains, including ensemble learning, weak-supervision, few-shot learning, neuromorphic and reservoir computing, adversarial and stealth attacks and natural language processing. </p> -->
        </tr>
        </tbody></table>
    </td></tr>
    </tbody></table>


    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:20px 5px;width:100%;vertical-align:middle;">
                    <h2 style="margin: 0; text-align: left;">Selected Works</h2>
                    <p>
                        Please see my
                        <a href="https://scholar.google.com/citations?hl=en&user=VY_Ldu4AAAAJ&view_op=list_works&sortby=pubdate"><i class="fa fa-graduation-cap"></i>Google Scholar</a> page for a full list of publications.
                    </p>
                </td>
            </tr>
        </tbody>
    </table>
    
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:10px;width:31%;vertical-align:top;">
                    <div style="display:table;height:100%;width:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <img src='images/stealth-edits.png' style="max-width: 100%; height: auto; display: block;">
                        </div>
                    </div>
                </td>
    
                <td style="padding:10px;width:70%;vertical-align:top;">
                    <div style="display:table;height:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <strong>Stealth edits for large language models</strong>
                            <br>
                            <a href="https://oliversutton.info/">Oliver J. Sutton*</a>,
                            <strong>Qinghua Zhou</strong>*, 
                            <a href="https://scholar.google.com/citations?user=BqlKMJ8AAAAJ&hl=en">Wei Wang</a>,
                            <a href="https://www.maths.ed.ac.uk/~dhigham/">Desmond J. Higham</a>,
                            <a href="https://scholar.google.co.uk/citations?user=D8XkcCIAAAAJ&hl=en">Alexander N. Gorban</a>, 
                            <a href="https://abastounis.com/">Alexander Bastounis</a>,
                            <a href="https://www.kcl.ac.uk/people/ivan-tyukin-1">Ivan Y Tyukin</a>
                            <br>
                            <em>NeurIPS</em>, 2024
                            <br>
                            <a class="main_color underline" href="https://arxiv.org/html/2406.12670v1">Paper</a>
                            |
                            <a class="main_color underline" href="https://github.com/qinghua-zhou/stealth-edits">Code</a>
                            |
                            <a class="main_color underline" href="https://huggingface.co/spaces/qinghua-zhou/stealth-edits">Huggingface Demo</a>
                            |
                            <a class="main_color underline" href="https://www.siam.org/publications/siam-news/articles/how-to-exploit-large-language-models-for-good-or-bad/">SIAM News Article</a>
                            <p>We expose the susceptibility of modern AI models to a new class of malicious attacks and reveal a new theoretical understanding of the causes behind this. This work enables us to either introduce external model components with easily 10,000 edits/layer with almost no impact on the model or hide an attack that is virtually impossible to detect, and even if the attack is found, it is impossible to determine the triggering prompt.  </p>
                        </div>
                    </div>
                </td>
            </tr>
        </tbody>
    </table>


    
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:10px;width:31%;vertical-align:top;">
                    <div style="display:table;height:100%;width:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <img src='images/adversarial.png' style="max-width: 100%; height: auto; display: block;">
                        </div>
                    </div>
                </td>
    
                <td style="padding:10px;width:70%;vertical-align:top;">
                    <div style="display:table;height:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <strong>How adversarial attacks can disrupt seemingly stable accurate classifiers</strong>
                            <br>
                            <a href="https://oliversutton.info/">Oliver J. Sutton</a>,
                            <strong>Qinghua Zhou</strong>, 
                            <a href="https://www.kcl.ac.uk/people/ivan-tyukin-1">Ivan Y Tyukin</a>,
                            <a href="https://scholar.google.co.uk/citations?user=D8XkcCIAAAAJ&hl=en">Alexander N. Gorban</a>, 
                            <a href="https://abastounis.com/">Alexander Bastounis</a>,
                            <a href="https://www.maths.ed.ac.uk/~dhigham/">Desmond J. Higham</a>
                            <br>
                            <em>Neural Networks</em>, 2024
                            <br>
                            <!-- <a class="main_color underline" href="https://www.sciencedirect.com/science/article/pii/S089360802400635X">Paper</a> -->
                            <p>We demonstrate a fundamental feature of classifiers working with high dimensional input data: simultaneous susceptibility of an 'accurate' model to adversarial attacks, and robustness to random perturbations of the input data. We provide theoretical framework and extensive empirical vertification that using additive noise during training or testing is inefficient for eradicating or detecting adversarial examples, and insufficient for certification of robustness! </p>
                        </div>
                    </div>
                </td>
            </tr>
        </tbody>
    </table>

    <!-- <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:10px;width:31%;vertical-align:top;">
                    <div style="display:table;height:100%;width:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <img src='images/cc.png' style="max-width: 100%; height: auto; display: block;">
                        </div>
                    </div>
                </td>
    
                <td style="padding:10px;width:70%;vertical-align:top;">
                    <div style="display:table;height:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <strong>Neuromorphic tuning of feature spaces to overcome the challenge of low-sample high-dimensional data</strong>
                            <br>
                            <strong>Qinghua Zhou</strong>, 
                            <a href="https://oliversutton.info/">Oliver J. Sutton</a>,
                            <a href="https://scholar.google.com/citations?user=A5lgIN8AAAAJ&hl=en&oi=ao">Yu-Dong Zhang</a>,
                            <a href="https://scholar.google.co.uk/citations?user=D8XkcCIAAAAJ&hl=en">Alexander N. Gorban</a>, 
                            <a href="https://www.ucm.es/imi/valeriy-a-makarov-slizneva">Valeri A. Makarov</a>,
                            <a href="https://www.kcl.ac.uk/people/ivan-tyukin-1">Ivan Y Tyukin</a>
                            <br>
                            <em>IJCNN</em>, 2023
                            <br>
                            <a class="main_color underline" href="https://ieeexplore.ieee.org/document/10191304">Paper</a> (Journal version in the works!)
                            <p>Here we consider a particular but very practical scenario in the HDLS domain where the number of training samples is not limited to mere few observations but yet it is not large enough to reliably build models with high degrees of expressivity. We present a neuromorphic algorithm capable of improving existing feature spaces via learning relevant associations in high dimensional data with high probability!</p>
                        </div>
                    </div>
                </td>
            </tr>
        </tbody>
    </table> -->


    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:10px;width:31%;vertical-align:top;">
                    <div style="display:table;height:100%;width:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <img src='images/mie.png' style="max-width: 100%; height: auto; display: block;">
                        </div>
                    </div>
                </td>
    
                <td style="padding:10px;width:70%;vertical-align:top;">
                    <div style="display:table;height:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <strong>Multiple-instance ensemble for construction of deep heterogeneous committees for high-dimensional low-sample-size data</strong>
                            <br>
                            <strong>Qinghua Zhou</strong>, 
                            <a href="https://scholar.google.com/citations?user=B-3bq-IAAAAJ&hl=en">Shuihua Wang</a>,
                            <a href="https://hengdezhu.github.io/">Hengde Zhu</a>, 
                            Xin Zhang,
                            <a href="https://scholar.google.com/citations?user=A5lgIN8AAAAJ&hl=en&oi=ao">Yu-Dong Zhang</a>,
                            <br>
                            <em>Neural Networks</em>, 2023
                            <br>
                            <!-- <a class="main_color underline" href="https://ieeexplore.ieee.org/document/9593931">Initial work</a>, <a class="main_color underline" href="https://www.sciencedirect.com/science/article/pii/S0893608023004483">Paper</a> -->
                            <p>Learning in the high dimensional and low-sample size (HDLS) domain is recognised as one of the core challenges for modern AI. Here we introduce a novel stacking method that utilises attention pooling mechanisms for ensembles and cascades. We provide extensive empirical experiments over a range of HDLS datasets in the medical domain.</p>
                        </div>
                    </div>
                </td>
            </tr>
        </tbody>
    </table>

    <!-- <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:10px;width:31%;vertical-align:top;">
                    <div style="display:table;height:100%;width:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <img src='images/ortho.png' style="max-width: 100%; height: auto; display: block;">
                        </div>
                    </div>
                </td>
    
                <td style="padding:10px;width:70%;vertical-align:top;">
                    <div style="display:table;height:100%;">
                        <div style="display:table-cell;vertical-align:top;">
                            <strong>Quasi-orthogonality and intrinsic dimensions as measures of learning and generalisation</strong>
                            <br>
                            <strong>Qinghua Zhou</strong>, 
                            <a href="https://scholar.google.co.uk/citations?user=D8XkcCIAAAAJ&hl=en">Alexander N. Gorban</a>, 
                            <a href="https://le.ac.uk/people/evgeny-mirkes">Evgeny M. Mirkes</a>,
                            <a href="https://scholar.google.com/citations?user=_5zJXc0AAAAJ&hl=en">Jonathan Bac</a>,
                            <a href="https://auranic.github.io/">Andrei Zinovyev</a>,
                            <a href="https://www.kcl.ac.uk/people/ivan-tyukin-1">Ivan Y Tyukin</a>
                            <br>
                            <em>IJCNN</em>, 2022
                            <br>
                            <a class="main_color underline" href="https://ieeexplore.ieee.org/document/9892337">Paper</a> 
                            <p>Here we examine correlations between the accuracies of trained networks and the values of some easily computable measures defined on randomly initialised networks. While prior works by Mellor et al. focused on volume-based measures, we examine measures of intrinsic dimensionality and quasi-orthogonality. Our empiricial observations further validates prior theoretical findings, and the work provides new measures and perspectives for zero-shot neural architectural search (NAS).</p>
                        </div>
                    </div>
                </td>
            </tr>
        </tbody>
    </table> -->


    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:20px 5px;width:100%;vertical-align:middle;">
                    <p>
                       More works can be found on my
                        <a href="https://scholar.google.com/citations?hl=en&user=VY_Ldu4AAAAJ&view_op=list_works&sortby=pubdate"><i class="fa fa-graduation-cap"></i>Google Scholar</a> page.
                    </p>
                </td>
            </tr>
        </tbody>
    </table>
    <footer>
        <p>© 2024 Qinghua Zhou. All Rights Reserved.</p>
    </footer>

</body>
  
</html>
